{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e297b4",
   "metadata": {},
   "source": [
    "Introduction to DataIngestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678de0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List,Dict,Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993bdfa",
   "metadata": {},
   "source": [
    "# Understanding Document Structure in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a simple document\n",
    "from langchain_core.documents import Document\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched\",\n",
    "    metadata={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"page\":1,\n",
    "        \"author\":\"Venkatesh\",\n",
    "        \"date_created\":\"2026-06-02\",\n",
    "        \"custom_filed\":\"any_value\"\n",
    "    }\n",
    "\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f765e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Document structure\n",
      "========================================================================================================================\n",
      "Content :This is the main text content that will be embedded and searched\n",
      "Metadata :{'source': 'example.txt', 'page': 1, 'author': 'Venkatesh', 'date_created': '2026-06-02', 'custom_filed': 'any_value'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing Document structure\")\n",
    "print(\"==\"*60)\n",
    "print(f\"Content :{doc.page_content}\")\n",
    "print(f\"Metadata :{doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingesting and Parsing Text data using Document.\n",
    "import os\n",
    "os.makedirs(\"data/textfiles\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts={\n",
    "    \"data/textfiles/python_intro.txt\":\"\"\"Python is a highâ€‘level, beginnerâ€‘friendly programming language created by Guido van Rossum in 1991. It is widely used for web development, data analysis, artificial intelligence, automation, and more because of its simple, readable syntax and powerful libraries. \n",
    "\n",
    "What is Python?\n",
    "General-purpose language: Can be used for web apps, desktop software, scripting, data science, and machine learning.\n",
    "\n",
    "Cross-platform: Works on Windows, macOS, Linux, and even Raspberry Pi.\n",
    "\n",
    "Interpreted: Code runs line by line, making it easier to test and debug.\n",
    "\n",
    "Open-source: Free to use, with a huge global community.\n",
    "\n",
    "Why Python is Popular\n",
    "Readable syntax: Its code looks close to English\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f028a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Text file s created !\n"
     ]
    }
   ],
   "source": [
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print (\"Simple Text file s created !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c10a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\RAG_KRISH\\RAG_UV\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/textfiles/python_intro.txt'}, page_content='Python is a highâ€‘level, beginnerâ€‘friendly programming language created by Guido van Rossum in 1991. It is widely used for web development, data analysis, artificial intelligence, automation, and more because of its simple, readable syntax and powerful libraries. \\n\\nWhat is Python?\\nGeneral-purpose language: Can be used for web apps, desktop software, scripting, data science, and machine learning.\\n\\nCross-platform: Works on Windows, macOS, Linux, and even Raspberry Pi.\\n\\nInterpreted: Code runs line by line, making it easier to test and debug.\\n\\nOpen-source: Free to use, with a huge global community.\\n\\nWhy Python is Popular\\nReadable syntax: Its code looks close to English')]\n",
      "Document Return type !  <class 'list'>\n",
      "Loaded 1 Documents\n",
      "content preview : Python is a highâ€‘level, beginnerâ€‘friendly programming language created by Guido van Rossum in 1991. \n",
      "Metadata: {'source': 'data/textfiles/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Loading a single file\n",
    "loader = TextLoader(\"data/textfiles/python_intro.txt\", encoding='utf-8')\n",
    "docuemnts = loader.load()\n",
    "\n",
    "print(docuemnts)\n",
    "print(\"Document Return type ! \"  , type(docuemnts))\n",
    "print(f\"Loaded {len(docuemnts)} Documents\")\n",
    "print(f\"content preview : {docuemnts[0].page_content[:100]}\")\n",
    "print(f\"Metadata: {docuemnts[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2636d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 123.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "\n",
      " Document 1: \n",
      "========================================================================================================================\n",
      " Source: data\\textfiles\\langchain.txt\n",
      "Length : 2200 characters\n",
      "\n",
      " Document 2: \n",
      "========================================================================================================================\n",
      " Source: data\\textfiles\\python_intro.txt\n",
      "Length : 672 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Text file from all the directories - Multiple text files\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# load all the text files from the directory\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/textfiles\",\n",
    "    glob=\"**/*.txt\" , # pattern to match text files\n",
    "    loader_cls =TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "docuemnts = dir_loader.load()\n",
    "\n",
    "print(f\"Loaded {len(docuemnts)} documents\")\n",
    "\n",
    "for i , doc in enumerate(docuemnts):\n",
    "    print(f\"\\n Document {i+1}: \")\n",
    "    print(\"==\"*60)\n",
    "    print(f\" Source: {doc.metadata['source']}\")\n",
    "    print(f\"Length : {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98440003",
   "metadata": {},
   "source": [
    "# Text splitting techinques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c86243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import(\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba404b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is an openâ€‘source framework that makes it easier to build applications powered by large language models (LLMs) like GPTâ€‘4. It helps developers connect models with external data, tools, and workflows, enabling advanced use cases such as chatbots, retrievalâ€‘augmented generation (RAG), and autonomous agents. \\n\\nðŸ” What LangChain Is\\nFramework for LLM apps: Provides building blocks to integrate language models with data sources, APIs, and tools.\\n\\nSupports Python & JavaScript: Widely accessible for developers in both ecosystems.\\n\\nAgent Architecture: Comes with preâ€‘built agent structures that can interact with multiple tools and adapt quickly.\\n\\nChains: Core concept where you define sequences of steps (like prompt â†’ model â†’ parser â†’ output).\\n\\nâœ¨ Key Features\\nModular Workflow: You can chain multiple steps together for reusable pipelines.\\n\\nPrompt Management: Tools for prompt engineering and memory handling.\\n\\nIntegrations: Works with OpenAI, Anthropic, Google, Hugging Face, and vector databases like Pinecone or Qdrant.\\n\\nLangChain Expression Language (LCEL): Lets you compose workflows declaratively using operators like |.\\n\\nRetrievalâ€‘Augmented Generation (RAG): Easily combine LLMs with external knowledge bases for more accurate answers. \\n\\nðŸ“Š Example Use Cases\\nUse Case\\tHow LangChain Helps\\nChatbots\\tManage conversation history, connect to APIs, and generate contextual responses.\\nSearch & RAG\\tRetrieve documents from vector stores and feed them into LLMs for grounded answers.\\nAutomation\\tBuild agents that can call external tools (like calculators, search engines).\\nData Analysis\\tParse and summarize large datasets using LLM pipelines.\\nâš¡ Benefits\\nRapid prototyping: Build an LLMâ€‘powered app in under 10 lines of code.\\n\\nFlexibility: Works with multiple models and tools.\\n\\nScalability: Supports production workflows with caching, monitoring, and deployment.\\n\\nCommunity support: Large ecosystem of tutorials, integrations, and openâ€‘source contributions.\\n\\nâœ… Summary\\nLangChain is essentially the â€œglueâ€ between LLMs and the outside world. It gives developers a structured way to build intelligent applications that donâ€™t just generate text but can also reason, retrieve data, and take actions.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = docuemnts[0].page_content\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9360c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 317, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len 12 chunks \n",
      "====================================================================================================\n",
      "First Chunk: LangChain is an openâ€‘source framework that makes it easier to build applications powered by large la...\n",
      "====================================================================================================\n",
      "Second Chunk: ðŸ” What LangChain Is\n",
      "Framework for LLM apps: Provides building blocks to integrate language models wi...\n"
     ]
    }
   ],
   "source": [
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function = len  # how to measure the chunk size\n",
    ")\n",
    "\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Len {len(char_chunks)} chunks \")\n",
    "print(\"==\"*50)\n",
    "print(f\"First Chunk: {char_chunks[0][:100]}...\")\n",
    "print(\"==\"*50)\n",
    "print(f\"Second Chunk: {char_chunks[1][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2dcbf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len 13 chunks \n",
      "====================================================================================================\n",
      "First Chunk: LangChain is an openâ€‘source framework that makes it easier to build applications powered by large language models (LLMs) like GPTâ€‘4. It helps developers connect models with external data, tools, and workflows, enabling advanced use cases such as chatbots, retrievalâ€‘augmented generation (RAG), and autonomous agents. ...\n",
      "====================================================================================================\n",
      "Second Chunk: ðŸ” What LangChain Is\n",
      "Framework for LLM apps: Provides building blocks to integrate language models with data sources, APIs, and tools....\n",
      "====================================================================================================\n",
      "Third Chunk: Supports Python & JavaScript: Widely accessible for developers in both ecosystems.\n",
      "\n",
      "Agent Architecture: Comes with preâ€‘built agent structures that can interact with multiple tools and adapt quickly....\n"
     ]
    }
   ],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    #separators=[\"\\n\\n\", \"\\n\" ,\" \",\"\"],\n",
    "    separators=[\"\\n\"],\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Len {len(recursive_chunks)} chunks \")\n",
    "print(\"==\"*50)\n",
    "print(f\"First Chunk: {recursive_chunks[0][:1000]}...\")\n",
    "print(\"==\"*50)\n",
    "print(f\"Second Chunk: {recursive_chunks[1][:1000]}...\")\n",
    "print(\"==\"*50)\n",
    "print(f\"Third Chunk: {recursive_chunks[2][:1000]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716affa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b84a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14221f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_UV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
